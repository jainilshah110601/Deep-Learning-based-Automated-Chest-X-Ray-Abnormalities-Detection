{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\nsubmission = pd.read_csv('../input/subsss/submission2.csv')\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install detectron2 -f \\\n  #https://dl.fbaipublicfiles.com/detectron2/wheels/cpu/torch1.7/index.html","metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n#from detectron2 import model_zoo\n#from detectron2.config import get_cfg, CfgNode\n#from detectron2.data import DatasetCatalog, MetadataCatalog,build_detection_train_loader, build_detection_test_loader, transforms, DatasetMapper, detection_utils\n#from detectron2.data.datasets import load_coco_json\n#from detectron2.engine import DefaultPredictor,DefaultTrainer\n#from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n#from detectron2.structures import BoxMode\n#from detectron2.utils.logger import setup_logger\n#setup_logger()\n#from detectron2.utils.visualizer import ColorMode, Visualizer\nfrom tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport random\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nimport shutil as sh\nimport yaml\nimport re\n\nfrom sklearn.utils import shuffle\nimport albumentations as A\nfrom copy import deepcopy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/vinbigdata-testmeta/test_meta.csv')\ndf.rename(columns={'dim0' : 'height','dim1':'width'},inplace=True)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data_Dir=\"../input/vinbigdata-chest-xray-abnormalities-detection\"\n\nTrain_Dir=os.path.join(Data_Dir,'train')\nTest_Dir=os.path.join(Data_Dir,'test')\n\nTrain_Dir_Files=[os.path.join(Train_Dir,name) for name in os.listdir(Train_Dir)]\nTest_Dir_Files=[os.path.join(Test_Dir,name) for name in os.listdir(Test_Dir)]\n\nprint(\"The total number of train dicom files :\",len(Train_Dir_Files))\nprint(\"The total number of test dicom files :\",len(Test_Dir_Files))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data_Dir_Resized='../input/vinbigdata-chest-xray-resized-png-256x256'\n\nTrain_Dir_Resized=f\"{Data_Dir_Resized}/train\"\nTest_Dir_Resized=f\"{Data_Dir_Resized}/test\"\n\nTrain_Dir_Files_Resized=[os.path.join(Train_Dir_Resized,name) for name in os.listdir(Train_Dir_Resized)]\nTest_Dir_Files_Resized=[os.path.join(Test_Dir_Resized,name) for name in os.listdir(Test_Dir_Resized)]\n\nprint(\"The total number of train dicom files :\",len(Train_Dir_Files))\nprint(\"The total number of test dicom files :\",len(Test_Dir_Files))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv=pd.read_csv(f\"{Data_Dir}/train.csv\")\nprint(\"Training DataFrame :\",format(len(train_csv)),\"entries\")\ntrain_csv.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_resized=pd.read_csv(f\"{Data_Dir_Resized}/train_meta.csv\")\ntrain_resized.rename(columns={'dim0':'height','dim1':'width'},inplace=True)\nprint(\"Metadata for Resized Training Images :\",format(len(train_resized)),\"entries\")\ntrain_resized.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_resized=pd.read_csv('../input/vinbigdata-testmeta/test_meta.csv')\ntest_resized.rename(columns={'dim0':'height','dim1':'width'},inplace=True)\nprint(\"Metadata for Resized Test Images :\",format(len(test_resized)),\"entries\")\ntest_resized.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_csv=pd.read_csv(\"../input/vinbigdata-chest-xray-abnormalities-detection/sample_submission.csv\")\nprint(\"Sample Submission DataFrame\")\nsub_csv.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_ids=pd.DataFrame(train_csv['image_id'].unique(),columns=['Image_ids'])\nprint(\"Unique Image Ids :\",len(image_ids),\"entries\")\nimage_ids.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes=pd.DataFrame(train_csv['class_name'].unique(),columns=['class_name'])\nclasses['class_id']=train_csv['class_id'].unique()\nclasses.set_index(['class_id'],inplace=True)\nclasses.sort_values(['class_id'],inplace=True)\n#classes['color_scheme']=classes['class_name'].apply(lambda x:[random.randint(0,255) for i in range(3)])\nclasses['color_scheme']=[[0,255,0],[255,0,0],[0,0,255],[255,255,0],[255,0,255],[0,255,255],\n                        [0,128,0],[128,0,0],[0,0,128],[128,128,0],[128,0,128],[0,128,128],\n                        [0,102,204],[153,204,0],np.nan]\nprint(\"Classes that can be predicted :\",len(classes),\"entries\")\nclasses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num = len(train_csv['rad_id'].unique())\nprint('Number of unique radiologists : ',num)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, x-ray is inverted:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n     \n    # normalize the numpy array\n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getBoxes(img_id):\n    boxes=pd.DataFrame(columns=['class_name','class_id','rad_id','bbox'])\n    for row in train_csv[train_csv['image_id']==img_id].to_numpy():\n        \n        # drop the 'No Finding' classes\n        if not np.isnan(row[4]):\n            boxes=boxes.append({'class_name':row[1],'class_id':row[2],'rad_id':row[3],'bbox':row[4:]},ignore_index=True)\n\n    return boxes\n    \ndef getImage_id(path):\n    return path[61:93]\n\ndef getcolor(name,isLabel):\n    if isLabel:\n        out=list(classes[classes['class_name']==name]['color_scheme'])[0]\n    else:\n        out=list(classes[classes['class_name']== name.split(':')[0][:-1]]['color_scheme'])[0]\n    return out\n    \ndef drawBoxes(path,reduced=True,opacity=0.1,boxes=None):\n    font=cv2.FONT_HERSHEY_SIMPLEX;\n    isLabel = False\n    \n    # convert ndarray to grayscale with 3 channels\n    img=cv2.cvtColor(read_xray(path),cv2.COLOR_GRAY2RGB)\n    if boxes is None:\n        isLabel = True\n        if reduced:\n            boxes=reduce_Boxes(getImage_id(path))\n        else:\n            boxes=getBoxes(getImage_id(path))\n    \n    # add annotations and bounding boxes\n    for row in boxes.to_numpy():\n        col = getcolor(row[0],isLabel)\n        rect = np.uint8(np.ones((int(row[3][3]-row[3][1]), int(row[3][2]-row[3][0]), 3))*col)\n        img=cv2.rectangle(img,(int(row[3][0]), int(row[3][1])),(int(row[3][2]), int(row[3][3])),col, 5)\n        sub_combo = cv2.addWeighted(img[int(row[3][1]):int(row[3][3]),int(row[3][0]):int(row[3][2]),:], 1-opacity, rect, opacity, 1.0)    \n        img[int(row[3][1]):int(row[3][3]),int(row[3][0]):int(row[3][2]),:] = sub_combo\n        img=cv2.putText(img,row[0],(int(row[3][0]), int(row[3][1])-12),font,2,col,4)\n    return img\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_imgs(imgs,size=7,cols=4,reduced=False,boxes=None):\n    rows=len(imgs)//cols + 1\n    fig=plt.figure(figsize=(rows*size,cols*size))\n    for i,path in enumerate(imgs):\n        if boxes is None:\n            img=drawBoxes(path,reduced)\n        else:\n            img=drawBoxes(path,reduced,boxes=boxes[i])\n        fig.add_subplot(rows,cols, i+1)\n        plt.imshow(img)\n    plt.show()\n    \ndef plot_img(path,reduced=False,figsize=(20,15),boxes=None):\n    img=drawBoxes(path,reduced,boxes=boxes)\n    fig=plt.figure(figsize=figsize)\n    fig.add_subplot(1,1,1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# output some randomly selected radiographs\nplot_imgs(random.choices(Train_Dir_Files,k=8))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#image_ids['count']=image_ids['Image_ids'].apply(lambda x: len(getBoxes(x)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"most_anno={'Image_ids':'03e6ecfa6f6fb33dfeac6ca4f9b459c9','count':57}\nleast_anno={'Image_ids':'b7b84cc718930bb70aa2fdcb53cfb98e','count':3}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#anno=image_ids.sort_values(['count'],ascending=False).reset_index(drop=True)\n#most_anno=anno.iloc[0]\nprint(\"The image/radiograph with most annotations (\"+str(most_anno['count'])+\") : \")\nplot_img(os.path.join(Train_Dir,str(most_anno['Image_ids'])+'.dicom'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#least_anno=anno[anno['count']!=0].sort_values(['count']).iloc[0]\nprint(\"The image/radiograph with least annotations (\"+str(least_anno['count'])+\") : \")\nplot_img(os.path.join(Train_Dir,str(least_anno['Image_ids'])+'.dicom'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the distribution of annotations per image\n#plt.figure(figsize=(12,8))\n#plt.xlabel('Number of Annotations per Image')\n#plt.ylabel('Number of Images')\n#sns.histplot(image_ids,bins=60)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def drawBoxes_rad(path,rad,reduced=False,opacity=0.1):\n    font=cv2.FONT_HERSHEY_SIMPLEX;\n    \n    # convert ndarray to grayscale with 3 channels\n    img=cv2.cvtColor(read_xray(path),cv2.COLOR_GRAY2RGB)\n    if reduced:\n        old_boxes=reduced_Boxes(getImage_id(path))\n    else:\n        old_boxes=getBoxes(getImage_id(path))\n    boxes=old_boxes[old_boxes['rad_id'] == rad]\n    boxes.reset_index(drop=True,inplace=True)\n    \n    # add annotations and bounding boxes\n    for row in boxes.to_numpy():\n        rect = np.uint8(np.ones((int(row[3][3]-row[3][1]), int(row[3][2]-row[3][0]), 3))*getcolor(row[0],True))\n        img=cv2.rectangle(img,\n                (int(row[3][0]), int(row[3][1])),\n                (int(row[3][2]), int(row[3][3])),\n                getcolor(row[0],True), 5)\n        sub_combo = cv2.addWeighted(img[int(row[3][1]):int(row[3][3]),int(row[3][0]):int(row[3][2]),:], 1-opacity, rect, opacity, 1.0)    \n        img[int(row[3][1]):int(row[3][3]),int(row[3][0]):int(row[3][2]),:] = sub_combo\n        img=cv2.putText(img,row[0],\n                (int(row[3][0]), int(row[3][1])-12),\n                 font,2,getcolor(row[0],True),4)\n    return img\n\ndef plot_img_rad(path,size=30,cols=4,reduced=False):\n    rads=list(train_csv[train_csv['image_id']==getImage_id(path)]['rad_id'].unique())\n    rows=len(rads)//cols + 1\n    fig=plt.figure(figsize=(rows*size,cols*size))\n    for i,rad in enumerate(rads):\n        img=drawBoxes_rad(path,rad,reduced)\n        fig.add_subplot(rows,cols, i+1)\n        plt.imshow(img)\n    plt.show()\n   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" plot_img_rad(os.path.join(Train_Dir,str(most_anno['Image_ids'])+'.dicom'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"boxes=getBoxes(most_anno['Image_ids'])\nboxes[boxes['rad_id']=='R9']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_iou(b1,b2):\n    x_left=max(b1[0],b2[0])\n    x_right=min(b1[2],b2[2])\n    y_top=max(b1[1],b2[1])\n    y_bottom=min(b1[3],b2[3]) \n    if x_right < x_left or y_bottom < y_top:\n        return 0\n    else:\n        intersec = max(0,x_right-x_left+1)*max(0,y_bottom-y_top+1)\n        union = ((b1[2]-b1[0]+1)*(b1[3]-b1[1]+1)) + ((b2[2]-b2[0]+1)*(b2[3]-b2[1]+1)) - intersec\n        return intersec/union\n\ndef getInnerBox(bboxes):\n    xmin = max([box[0] for box in bboxes])\n    ymin = max([box[1] for box in bboxes])\n    xmax = min([box[2] for box in bboxes])\n    ymax = min([box[3] for box in bboxes])\n    if (xmax-xmin < 10) or (ymax-ymin < 10) :\n        return None\n    else:\n        return [xmin, ymin, xmax, ymax]\n            \ndef reduce_Boxes(img_id):\n    boxes=getBoxes(img_id)\n    new_boxes=pd.DataFrame(columns=['class_name','class_id','rad_id','bbox'])\n    for row in boxes.to_numpy():\n        rad=row[2]\n        class_id=row[1]\n        class_name=row[0]\n        bbox=row[3]\n        invalid_boxes=[bbox,]\n        for row in boxes.to_numpy():\n            if row[1] == class_id:\n                other_box=row[3]\n                if other_box.all() != bbox.all():\n                    iou=calc_iou(bbox,other_box)\n                    if iou > 0:\n                        invalid_boxes.append(other_box)\n        if (len(invalid_boxes)) >= 1:\n            inner_box=getInnerBox(invalid_boxes)\n            if inner_box and inner_box not in list(new_boxes['bbox']):\n                new_boxes=new_boxes.append({'class_name':class_name,'class_id':class_id,\n                                            'rad_id':rad,'bbox':inner_box},ignore_index=True)\n    return new_boxes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"getBoxes(most_anno['Image_ids'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduce_Boxes(most_anno['Image_ids'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_img(os.path.join(Train_Dir,str(most_anno['Image_ids'])+'.dicom'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_img(os.path.join(Train_Dir,str(most_anno['Image_ids'])+'.dicom'),True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"not_a real_function()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yolo_predict = pd.read_csv('../input/yolov5-sub/submission_yoloV5 (1).csv')\nyolo_predict['PredictionString'] = yolo_predict['PredictionString'].apply(lambda x : list(map(float,x.split(' '))))\nyolo_predict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getTestBoxes_yolo(img_id,conf=0.005):\n    boxes=pd.DataFrame(columns=['label','class_id','conf','bbox'])\n    predictions = list(yolo_predict[yolo_predict['image_id']==img_id]['PredictionString'])[0]\n    for i in range(0,len(predictions),6):\n        if predictions[i+1] >= conf:\n            boxes=boxes.append({'label': (str(classes.iloc[int(predictions[i])]['class_name']) + \" : \"+str(predictions[i+1])),\n                                'class_id':int(predictions[i]),\n                                'conf': str(predictions[i+1]),\n                                'bbox':predictions[i+2:i+6]},ignore_index=True)\n    return boxes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_id = '0a08191a658edb1327e7282045ec71cf'\ngetTestBoxes_yolo(img_id,0.008)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_img(f'{Test_Dir}/{img_id}.dicom',boxes=getTestBoxes_yolo(img_id,0.01))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rand = random.choices(yolo_predict['image_id'],k=8)\nboxes = [getTestBoxes_yolo(r) for r in rand]\nfiles = [f'{Test_Dir}/{r}.dicom' for r in rand]\nplot_imgs(files,boxes=boxes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai import *\nfrom fastai.vision.all import *\n\nfrom sklearn.utils import shuffle\n\n#from object_detection_fastai.helper.object_detection_helper import *\n#from object_detection_fastai.loss.RetinaNetFocalLoss import RetinaNetFocalLoss\n#from object_detection_fastai.models.RetinaNet import RetinaNet\n#from object_detection_fastai.callbacks.callbacks import BBLossMetrics, BBMetrics, PascalVOCMetric","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install object-detection-fastai","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_fastai(debug=True,validate=True,use_reduced=False):\n    dataset={}\n    data=train_resized\n    if validate:\n        data=train_resized[:13500]\n    if debug:\n        data=train_resized[:1000]\n    if use_reduced:\n        Boxes=reduce_Boxes\n    else:\n        Boxes=getBoxes\n        \n    img_id=data['image_id'][0]\n    img=cv2.imread(f'{Train_Dir_Resized}/{img_id}.png')\n    height=img.shape[0]\n    width=img.shape[1]\n    \n    for data_row in data.to_numpy():\n        file = f'{Train_Dir_Resized}/{data_row[0]}.png'\n        h_ratio=height/data_row[1]\n        w_ratio=width/data_row[2]\n        anno=[]\n        cat=[]\n        for anno_row in Boxes(data_row[0]).to_numpy():\n            anno_rec=[round(anno_row[3][0]*w_ratio,3),\n                      round(anno_row[3][1]*h_ratio,3),\n                      round(anno_row[3][2]*w_ratio,3),\n                      round(anno_row[3][3]*h_ratio,3)]\n            cat_rec = anno_row[0]\n            anno.append(anno_rec)\n            cat.append(cat_rec)\n        dataset[file]=[anno,cat]\n    \n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_resized = shuffle(train_resized)\ntrain_resized.reset_index(drop=True,inplace=True)\n\ntest_train=get_train_fastai()\n\ntrain_demo=train_resized[:1000]\ntrain_demo['filename'] = train_demo['image_id'].apply(lambda x: f'{Train_Dir_Resized}/{x}.png')\ntrain_demo['bbox'] = train_demo['image_id'].apply(lambda x: test_train[f'{Train_Dir_Resized}/{x}.png'][0])\ntrain_demo['bboxlbl'] = train_demo['image_id'].apply(lambda x: test_train[f'{Train_Dir_Resized}/{x}.png'][1])\ntrain_demo['is_valid'] =  train_demo['image_id'].apply(lambda x: True)\n\ntrain_demo.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_pascal_train(x):\n    return (x.filename,test_train[x][0],test_train[x][1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#chest = DataBlock(\n#                  blocks=(ImageBlock, BBoxBlock, BBoxLblBlock),\n #                 splitter = IndexSplitter(train_demo.index),\n  #                get_x = ColReader(3),\n  #                 get_y =[ColReader(4),ColReader(5)],\n  #                item_tfms = Resize(256),\n  #                batch_tfms = aug_transforms(),\n  #                n_inp = 1\n  #                )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dls = chest.dataloaders(train_demo,num_workers=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_dicts(debug=False,validate=True,use_reduced=False):\n    dataset=[]\n    data=train_resized\n    if validate:\n        data=train_resized[:13500]\n    if debug:\n        data=train_resized[:1000]\n    if use_reduced:\n        Boxes=reduce_Boxes\n    else:\n        Boxes=getBoxes\n        \n    img_id=data['image_id'][0]\n    img=cv2.imread(f'{Train_Dir_Resized}/{img_id}.png')\n    height=img.shape[0]\n    width=img.shape[1]\n    \n    for data_row in data.to_numpy():\n        record={}\n        record['image_id']=data_row[0]\n        record['file_name']=f'{Train_Dir_Resized}/{data_row[0]}.png'\n        record['height']=height\n        record['width']=width\n        h_ratio=height/data_row[1]\n        w_ratio=width/data_row[2]\n        anno=[]\n        for anno_row in Boxes(data_row[0]).to_numpy():\n            anno_rec={}\n            anno_rec['bbox']=[round(anno_row[3][0]*w_ratio,3),\n                              round(anno_row[3][1]*h_ratio,3),\n                              round(anno_row[3][2]*w_ratio,3),\n                              round(anno_row[3][3]*h_ratio,3)]\n            anno_rec['bbox_mode']=BoxMode.XYXY_ABS\n            anno_rec['category_id']=anno_row[1]\n            anno.append(anno_rec)\n        record['annotations']=anno\n        dataset.append(record)\n    \n    return dataset\n\ndef get_valid_dicts(debug=False,validate=True,use_reduced=False):\n    dataset=[]\n    data=train_resized\n    if validate:\n        data=train_resized[13500:]\n        data.reset_index(drop=True,inplace=True)\n    if debug:\n        data=train_resized[2000:2100]\n        data.reset_index(drop=True,inplace=True)\n    if use_reduced:\n        Boxes=reduce_Boxes\n    else:\n        Boxes=getBoxes\n        \n    img_id=data['image_id'][0]\n    img=cv2.imread(f'{Train_Dir_Resized}/{img_id}.png')\n    height=img.shape[0]\n    width=img.shape[1]\n    \n    for data_row in data.to_numpy():\n        record={}\n        record['image_id']=data_row[0]\n        record['file_name']=f'{Train_Dir_Resized}/{data_row[0]}.png'\n        record['height']=height\n        record['width']=width\n        h_ratio=height/data_row[1]\n        w_ratio=width/data_row[2]\n        anno=[]\n        for anno_row in Boxes(data_row[0]).to_numpy():\n            anno_rec={}\n            anno_rec['bbox']=[round(anno_row[3][0]*w_ratio,3),\n                              round(anno_row[3][1]*h_ratio,3),\n                              round(anno_row[3][2]*w_ratio,3),\n                              round(anno_row[3][3]*h_ratio,3)]\n            anno_rec['bbox_mode']=BoxMode.XYXY_ABS\n            anno_rec['category_id']=anno_row[1]\n            anno.append(anno_rec)\n        record['annotations']=anno\n        dataset.append(record)\n    \n    return dataset\n\ndef get_test_dicts(debug=False):\n    dataset=[]\n    data=test_resized\n    if debug:\n        data=test_resized[:50]\n        \n    img_id=data['image_id'][0]\n    img=cv2.imread(f'{Test_Dir_Resized}/{img_id}.png')\n    height=img.shape[0]\n    width=img.shape[1]\n    \n    for data_row in data.to_numpy():\n        record={}\n        record['image_id']=data_row[0]\n        record['file_name']=f'{Test_Dir_Resized}/{data_row[0]}.png'\n        record['height']=height\n        record['width']=width\n        dataset.append(record)\n        \n    return dataset\n\ndef visualize_traindata(dicts,size=13,cols=4):\n    meta_data=MetadataCatalog.get('Chest_abnormalities')\n    rows=len(dicts)//cols + 1\n    fig=plt.figure(figsize=(rows*size,cols*size))\n    for i,d in enumerate(dicts):\n        img = cv2.imread(d['file_name'])\n        visualizer = Visualizer(img[:,:,::-1], metadata=meta_data)\n        vis = visualizer.draw_dataset_dict(d)\n        fig.add_subplot(rows,cols, i+1)\n        plt.imshow(vis.get_image()[:,:,::-1])\n    plt.show()\n    \ndef visualize_testdata(dicts,predictor:DefaultPredictor,size=14,cols=4):\n    meta_data=MetadataCatalog.get('Chest_abnormalities_test')\n    rows=len(dicts)//cols + 1\n    fig=plt.figure(figsize=(rows*size,cols*size))\n    for i,d in enumerate(dicts):\n        img = cv2.imread(d['file_name'])\n        outputs = predictor(img)\n        v = Visualizer(img[:, :, ::-1],\n                   metadata=meta_data, \n                   scale=0.8,\n                   instance_mode=ColorMode.IMAGE   \n        )\n        v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n        fig.add_subplot(rows,cols, i+1)\n        plt.imshow(v.get_image()[:,:,::-1])\n    plt.show()\n\ndef format_predictions(fields,dim0,dim1,resized_height=256,resized_width=256):\n    preds=[]\n    pred_classes=fields['pred_classes'].cpu().numpy()\n    pred_boxes=fields['pred_boxes'].tensor.cpu().numpy()\n    scores=fields['scores'].cpu().numpy()\n    h_ratio = dim0 / resized_height\n    w_ratio = dim1 / resized_width\n    pred_boxes[:, [0, 2]] *= w_ratio\n    pred_boxes[:, [1, 3]] *= h_ratio\n    for label,score,box in zip(pred_classes,scores,pred_boxes):\n        xmin, ymin, xmax, ymax =box.astype(np.int64)\n        preds.append(f'{label} {score} {xmin} {ymin} {xmax} {ymax}')\n    return \" \".join(preds)\n\ndef get_test_predictions(predictor:DefaultPredictor):\n    dataset=[]\n    for test_row in test_resized.to_numpy():\n        img=cv2.imread(f'{Test_Dir_Resized}/{test_row[0]}.png')\n        out=predictor(img)\n        if len(out['instances'])==0:\n            pred_string='14 1.0 0 0 1 1'\n        else:\n            pred_string=format_predictions(out['instances'].get_fields(),test_row[1],test_row[2])\n        record={'image_id':test_row[0],'PredictionString':pred_string,}\n        dataset.append(record)\n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DatasetCatalog.register('Chest_abnormalities',lambda: get_train_dicts())\nMetadataCatalog.get('Chest_abnormalities').thing_classes=list(classes['class_name'][:14])\n#DatasetCatalog.remove('Chest_abnormalities')\n#MetadataCatalog.remove('Chest_abnormalities')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dataset_dicts = get_train_dicts()\n#visualize_traindata(random.sample(dataset_dicts, 4))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_data=MetadataCatalog.get('Chest_abnormalities')\nmeta_data.thing_classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DatasetCatalog.register('Chest_abnormalities_valid',lambda: get_valid_dicts())\nMetadataCatalog.get('Chest_abnormalities_valid').thing_classes=list(classes['class_name'][:14])\n#dataset_dicts=get_valid_dicts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DatasetCatalog.register('Chest_abnormalities_test',lambda: get_test_dicts())\nMetadataCatalog.get('Chest_abnormalities_test').thing_classes=list(classes['class_name'][:14])\n#dataset_dicts=get_test_dicts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AlbumentationMapper:\n    \n    def __init__(self,cfg,is_train=True):\n        augs = cfg.aug_kwargs;\n        aug_list = []\n        if is_train:\n            aug_list.extend(getattr(A,func)(**args) for func,args in augs.items())\n        self.transform = A.Compose(aug_list, bbox_params=A.BboxParams(format = 'pascal_voc',label_fields=[\"category_ids\"]))\n        self.is_train=is_train\n        \n    def __call__(self,dataset_dict):\n        dataset = deepcopy(dataset_dict)\n        old_anno = dataset['annotations']\n        old_boxes = np.array([obj['bbox'] for obj in old_anno] , dtype=np.float32)\n        cats = np.arange(len(dataset['annotations']))\n        \n        img = detection_utils.read_image(dataset['file_name'], format='BGR')\n        trans_img = self.transform(image=img ,bboxes=old_boxes ,category_ids=cats)\n        img = trans_img['image']\n        new_anno=[]\n        for i,j in enumerate(trans_img['category_ids']):\n            d = old_anno[j]\n            d['bbox'] = trans_img[\"bboxes\"][i]\n            new_anno.append(d)\n        dataset.pop('annotations',None)\n       \n        img_shape = img.shape[:2]\n        dataset[\"image\"] = torch.as_tensor(img.transpose(2, 0, 1).astype(\"float32\"))\n        instances = detection_utils.annotations_to_instances(new_anno, img_shape)\n        dataset[\"instances\"] = detection_utils.filter_empty_instances(instances)\n        return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomTrainer(DefaultTrainer):\n    \n    @classmethod\n    def build_train_loader(cls,cfg,sampler=None):\n        #return build_detection_train_loader(cfg, mapper=AlbumentationMapper(cfg, True) ,sampler=sampler)\n        return build_detection_train_loader(cfg, mapper=None ,sampler=sampler)\n    \n    @classmethod\n    def build_test_loader(cls, cfg, dataset_name):\n        #return build_detection_test_loader(cfg, dataset_name, mapper=AlbumentationMapper(cfg, False))\n        return build_detection_test_loader(cfg, dataset_name, mapper=None)\n        \n    @classmethod\n    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n        if output_folder is None:\n            output_folder = os.path.join(cfg.OUTPUT_DIR,\"inference\")\n        return COCOEvaluator(dataset_name, ('bbox',), True, output_folder)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg=get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n\ncfg.aug_kwargs = CfgNode({\"HorizontalFlip\": {\"p\": 0.4},\n                  \"ShiftScaleRotate\": {\"scale_limit\": 0.20, \"rotate_limit\": 20, \"p\": 0.4}})\n\ncfg.OUTPUT_DIR = f'results/'\n\ncfg.DATASETS.TRAIN = ('Chest_abnormalities',)\ncfg.DATASETS.TEST = ('Chest_abnormalities_valid',)\ncfg.DATALOADER.NUM_WORKERS = 4\n\ncfg.MODEL.DEVICE='cuda'\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_SIZE = 512\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = len(meta_data.thing_classes)\n\ncfg.SOLVER.MAX_ITER = 50000\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.BASE_LR = 0.00025\n\ncfg.TEST.EVAL_PERIOD = 10000\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.aug_kwargs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#not_a_real_function(not_a_real_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#trainer=CustomTrainer(cfg)\n#trainer.resume_or_load(resume=False)\n#trainer.train()\n#not_a_real_function(not_a_real_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/data-subs-30000/submission (2).csv')\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR,'model_final.pth')\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\npredictor=DefaultPredictor(cfg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_dicts = get_test_dicts()\nimg = cv2.imread(dataset_dicts[1]['file_name'])\noutputs = predictor(img)\noutputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results=get_test_predictions(predictor)\nsubmission = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\nsubmission.to_csv(\"submission_0.5.csv\", index=False)\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#not_a_real_function(not_a_real_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE = 256","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_yolo():\n    dataset = train_csv\n    dataset = dataset.merge(train_resized, on='image_id', how='left')\n    dataset['x_min_resize'] = round(dataset['x_min']*SIZE/dataset['width'],0)\n    dataset['x_max_resize'] = round(dataset['x_max']*SIZE/dataset['width'],0)\n    dataset['y_min_resize'] = round(dataset['y_min']*SIZE/dataset['height'],0)\n    dataset['y_max_resize'] = round(dataset['y_max']*SIZE/dataset['height'],0)\n    dataset['x_center'] = round((dataset['x_max_resize']+dataset['x_min_resize'])/2,1)\n    dataset['y_center'] = round((dataset['y_max_resize']+dataset['y_min_resize'])/2,1)\n    dataset['width_resize'] = round(dataset['x_max_resize']-dataset['x_min_resize'],1)\n    dataset['height_resize'] = round(dataset['y_max_resize']-dataset['y_min_resize'],1)\n    dataset = dataset[['image_id','class_name','class_id','rad_id','x_center','y_center','width_resize','height_resize']]\n    dataset.rename(columns = {'width_resize':'w','height_resize':'h'},inplace=True)\n    return dataset\n\ndef getXYHWBoxes(allbox):\n    boxes=[]\n    for row in allbox.to_numpy():\n        # drop the 'No Finding' classes\n        if not np.isnan(row[4]):\n            boxes.append(f'{row[2]} {row[4]/SIZE} {row[5]/SIZE} {row[6]/SIZE} {row[7]/SIZE}')\n    return boxes\n\ndef create_files_yolo(train_file='./chest-yolo',debug=False):\n    data=preprocess_yolo()\n    data = shuffle(data)\n    data.reset_index(drop=True,inplace=True)\n    if debug:\n        train = data['image_id'].unique()[:500]\n        val = data['image_id'].unique()[500:600]\n    else:\n        train = data['image_id'].unique()[:13000]\n        val = data['image_id'].unique()[13000:]\n\n    os.makedirs(f'{train_file}/images/train', exist_ok=True)\n    os.makedirs(f'{train_file}/labels/train', exist_ok=True)\n    os.makedirs(f'{train_file}/images/val', exist_ok=True)\n    os.makedirs(f'{train_file}/labels/val', exist_ok=True)\n    \n    for img in train:\n        boxes = getXYHWBoxes(data[data['image_id']==img])\n        with open(f'{train_file}/labels/train/{img}.txt', 'w+') as f:\n            for box in boxes:\n                f.write(box)\n                f.write('\\n')\n        sh.copy(f'{Train_Dir_Resized}/{img}.png',\n                f'{train_file}/images/train/{img}.png')\n        \n    for img in val:\n        boxes = getXYHWBoxes(data[data['image_id']==img])\n        with open(f'{train_file}/labels/val/{img}.txt', 'w+') as f:\n            for box in boxes:\n                f.write(box)\n                f.write('\\n')\n        sh.copy(f'{Train_Dir_Resized}/{img}.png',\n                f'{train_file}/images/val/{img}.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = preprocess_yolo()\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_files_yolo()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone  'https://github.com/ultralytics/yolov5.git'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -R","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv yolov5/* ./\n!mv ./* ./","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -qr requirements.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!echo -e 'train: ./chest-yolo/images/train\\nval: ./chest-yolo/images/val\\n\\nnc: 14\\nnames: ['Aortic enlargement','Atelectasis','Calcification','Cardiomegaly','Consolidation','ILD','Infiltration','Lung Opacity','Nodule/Mass','Other lesion','Pleural effusion','Pleural thickening','Pneumothorax','Pulmonary fibrosis']' >> bcc.yaml\n!cat 'bcc.yaml'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sed -i 's/nc: 80/nc: 14/g' ./models/yolov5x.yaml","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./models/yolov5x.yaml') as f:\n    dictionary = yaml.load(f)\n    for key,value in dictionary.items():\n        print(key+':'+str(value))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wandb disabled","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python ./train.py --epochs 20 --batch-size 4 --cfg ./models/yolov5x.yaml \\\n--data ./bcc.yaml --img 256 --name Chest1 --device 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(\"./runs/train/Chest1/weights/best.pt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#./runs/train/Chest1/weights/best.pt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python ./detect.py --weights ./runs/train/Chest1/weights/best.pt \\\n--img-size 256 --conf-thres 0.005 --source ../input/vinbigdata-chest-xray-resized-png-256x256/test --iou-thres 0.40 \\\n--save-txt --save-conf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RESULTS = './runs/detect/exp/labels'\n\ndef process_labels(path,shape):\n    with open(path,'r') as f:\n        read = f.read()\n        detect_result = re.split(r'[\\n]', read)[:-1]\n        records = []\n        for row in detect_result:\n            record = list(map(float,re.split(r'[ ]', row)))\n            x_cen,y_cen = record[1]*SIZE,record[2]*SIZE\n            w,h = record[3]*SIZE,record[4]*SIZE\n            h_ratio = shape[0] / SIZE\n            w_ratio = shape[1] / SIZE\n            record[0] = int(record[0])\n            record[1] = round(record[5],3)\n            record[2] = int((x_cen - 0.5*w) * w_ratio)\n            record[3] = int((y_cen - 0.5*h) * h_ratio)\n            record[4] = int((x_cen + 0.5*w) * w_ratio)\n            record[5] = int((y_cen + 0.5*h) * h_ratio)\n            records.append(f'{record[0]} {record[1]} {record[2]} {record[3]} {record[4]} {record[5]}')\n        return ' '.join(records)\n    \ndef read_labels():\n    dataset = []\n    for row in test_resized.to_numpy():\n        path = os.path.join(f'{RESULTS}/{row[0]}.txt')\n        if os.path.isfile(path):\n            results = process_labels(path,row[1:])\n        else:\n            results = '14 1 0 0 1 1'\n        record={'image_id':row[0],'PredictionString':results,}\n        dataset.append(record)\n    return dataset\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results=read_labels()\nsubmission = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\nsubmission.to_csv(\"submission_yoloV5.csv\", index=False)\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(os.path.join(\"submission.csv\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_dicts = get_test_dicts()\n\n#Threshold_score = 0.5\nsample_data=random.sample(dataset_dicts, 4)\nvisualize_testdata(sample_data,predictor)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Threshold_score = 0\nvisualize_testdata(sample_data,predictor)  ","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#evaluator = COCOEvaluator('Chest_abnormalities_valid','bbox',False, output_dir=cfg.OUTPUT_DIR)\n#val_loader = build_detection_test_loader(cfg, 'Chest_abnormalities_valid')\n\n#inference_on_dataset(predictor.model, val_loader, evaluator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#evaluator = COCOEvaluator(\"Chest_abnormalities_test\",'bbox',False, output_dir=cfg.OUTPUT_DIR)\n#val_loader = build_detection_test_loader(cfg, \"Chest_abnormalities_test\")\n\n#inference_on_dataset(predictor.model, val_loader, evaluator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evals = pd.read_json('./results/metrics.json',orient='records',lines=True)\nevals.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots(1,2,figsize=(16,6)) \nfig.suptitle('Loss Curves')\nax[0].plot(evals['iteration'],evals['loss_box_reg'])\nax[1].plot(evals['iteration'],evals['loss_cls'])\nax[0].set_xlabel('No. of Iterations')\nax[1].set_xlabel('No. of Iterations')\nax[0].set_ylabel('Classification Loss')\nax[1].set_ylabel('Box Regression Loss')\nax[1].set_ylim([0,0.6])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots(1,2,figsize=(16,6)) \nfig.suptitle('ROIS per image')\nax[0].plot(evals['iteration'],evals['roi_head/num_fg_samples'])\nax[1].plot(evals['iteration'],evals['roi_head/num_bg_samples'])\nax[0].set_xlabel('No. of Iterations')\nax[1].set_xlabel('No. of Iterations')\nax[0].set_ylabel('No. of foreground proposals')\nax[1].set_ylabel('No. of foreground proposals')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nmdf_bbox_class = evals.iloc[-1][[f\"bbox/AP-{col}\" for col in meta_data.thing_classes]]\nmdf_bbox_class.plot(kind=\"bar\", ax=ax)\nax.set_title(\"AP by class\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}